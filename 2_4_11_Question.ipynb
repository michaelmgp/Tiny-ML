{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2-4-11-Question.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktqTCGHJw-ws"
      },
      "source": [
        "# Bean Disease Classifier\n",
        "For this assignment you'll take what you've learned so far and build a classifier for bean disease. You'll be provided with training and validation data based on 224x224 pixel color images taken of bean plants in Uganda. These images show healthy bean leaves as well as 2 types of common disease: bean rust and angular leaf spots. Your job will be to build a neural network that can tell the difference between the healthy and diseased leaves.\n",
        "\n",
        "We start by setting up the problem for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmnkg6vGbX1t"
      },
      "source": [
        "# Do not change this code\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njf4YhwFb6hW",
        "outputId": "5e032793-5436-4370-df17-818a17ade5f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Do not change this code\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/ibeans/train.zip \\\n",
        "    -O /tmp/train.zip\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/ibeans/validation.zip \\\n",
        "    -O /tmp/validation.zip\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/ibeans/test.zip \\\n",
        "    -O /tmp/test.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-02 15:48:57--  https://storage.googleapis.com/ibeans/train.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.157.128, 74.125.23.128, 74.125.203.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.157.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 143812152 (137M) [application/zip]\n",
            "Saving to: ‘/tmp/train.zip’\n",
            "\n",
            "/tmp/train.zip      100%[===================>] 137.15M  42.9MB/s    in 3.2s    \n",
            "\n",
            "2021-09-02 15:49:02 (42.9 MB/s) - ‘/tmp/train.zip’ saved [143812152/143812152]\n",
            "\n",
            "--2021-09-02 15:49:02--  https://storage.googleapis.com/ibeans/validation.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.157.128, 74.125.23.128, 74.125.203.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.157.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18504213 (18M) [application/zip]\n",
            "Saving to: ‘/tmp/validation.zip’\n",
            "\n",
            "/tmp/validation.zip 100%[===================>]  17.65M  26.7MB/s    in 0.7s    \n",
            "\n",
            "2021-09-02 15:49:04 (26.7 MB/s) - ‘/tmp/validation.zip’ saved [18504213/18504213]\n",
            "\n",
            "--2021-09-02 15:49:04--  https://storage.googleapis.com/ibeans/test.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.188.128, 64.233.189.128, 108.177.97.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.188.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17708541 (17M) [application/zip]\n",
            "Saving to: ‘/tmp/test.zip’\n",
            "\n",
            "/tmp/test.zip       100%[===================>]  16.89M   112MB/s    in 0.2s    \n",
            "\n",
            "2021-09-02 15:49:04 (112 MB/s) - ‘/tmp/test.zip’ saved [17708541/17708541]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KscpTrSWcK1T"
      },
      "source": [
        "# Do not change this code\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/train.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "local_zip = '/tmp/validation.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "local_zip = '/tmp/test.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/test')\n",
        "zip_ref.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQe37rwjML3o"
      },
      "source": [
        "Now you need to define a generator to process the data we have loaded in Colab so that our model can use it for training. As we showed in the previous video you'll first have to define an ```ImageDataGenerator``` and then flow the data into it.\n",
        "\n",
        "*A hint: You don't want abnormal data!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCiSd248caB4",
        "outputId": "7f659b8e-9bf3-4474-d833-a5936c230f27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255 , # YOUR CODE HERE #\n",
        "\n",
        "    rotation_range=40,\n",
        "\n",
        "    width_shift_range=0.2,\n",
        "\n",
        "    height_shift_range=0.2,\n",
        "\n",
        "    shear_range=0.2,\n",
        "\n",
        "    zoom_range=0.2,\n",
        "\n",
        "    horizontal_flip=True,\n",
        "\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "      \n",
        "    rescale=1./255 , # YOUR CODE HERE #\n",
        "\n",
        "    rotation_range=40,\n",
        "\n",
        "    width_shift_range=0.2,\n",
        "\n",
        "    height_shift_range=0.2,\n",
        "\n",
        "    shear_range=0.2,\n",
        "\n",
        "    zoom_range=0.2,\n",
        "\n",
        "    horizontal_flip=True,\n",
        "\n",
        "    fill_mode='nearest'# YOUR CODE HERE #\n",
        ")\n",
        "\n",
        "TRAIN_DIRECTORY_LOCATION = '/tmp/train' # YOUR CODE HERE #\n",
        "VAL_DIRECTORY_LOCATION = '/tmp/validation' # YOUR CODE HERE #\n",
        "TARGET_SIZE = (224,224) # YOUR CODE HERE #\n",
        "CLASS_MODE = 'categorical' # YOUR CODE HERE #\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIRECTORY_LOCATION,\n",
        "    target_size = TARGET_SIZE,  \n",
        "    batch_size = 128,\n",
        "    class_mode = CLASS_MODE\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    VAL_DIRECTORY_LOCATION,\n",
        "    target_size = TARGET_SIZE,  \n",
        "    batch_size = 128,\n",
        "    class_mode = CLASS_MODE\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1034 images belonging to 3 classes.\n",
            "Found 133 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myaca4qSML3s"
      },
      "source": [
        "Now its your turn to define a model to learn this data. \n",
        "\n",
        "*A hint: Like with the CIFAR-10 assignment, your model may want to learn some high level features and then classify them. This time it may help to make the model a little wider at times.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrJt6YSDcqjX",
        "outputId": "1528f12b-eda2-4453-82ee-e50476b8af38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.Sequential([\n",
        "  # Find the features with Convolutions and Pooling\n",
        "\n",
        "   tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "\n",
        "   tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "   tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "\n",
        "   tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "   tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "\n",
        "   tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "   tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "\n",
        "   tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "   # Flatten the results to feed into a DNN\n",
        "\n",
        "   tf.keras.layers.Flatten(),\n",
        "\n",
        "   # 512 neuron hidden layer\n",
        "\n",
        "   tf.keras.layers.Dense(512, activation='relu'),\n",
        "\n",
        "   tf.keras.layers.Dense(3, activation='softmax')  #YOUR CODE HERE#\n",
        "])\n",
        "\n",
        "# This will print a summary of your model when you're done!\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 222, 222, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 111, 111, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 109, 109, 32)      4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 52, 52, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               9437696   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 9,536,675\n",
            "Trainable params: 9,536,675\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhw5AhDhML3v"
      },
      "source": [
        "Then you'll need to pick an appropriate loss function and optimizer.\n",
        "\n",
        "*A hint: remember we are classifying again.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nST6CyvCcy-2"
      },
      "source": [
        "LOSS_FUNCTION = 'categorical_crossentropy'  #YOUR CODE HERE#\n",
        "OPTIMIZER = 'adam'#YOUR CODE HERE#\n",
        "\n",
        "model.compile(\n",
        "    loss = LOSS_FUNCTION,\n",
        "    optimizer = OPTIMIZER,\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l14_QnwmML3y"
      },
      "source": [
        "Finally select the number of epochs you'd like to train for and train your model!\n",
        "\n",
        "*A hint: something in the low tens is a good place to start*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3iK9LX9deu2",
        "outputId": "b831b8cc-e779-4f69-d43a-9843bf2bd6aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "NUM_EPOCHS =20 #YOUR CODE HERE#\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator, \n",
        "      epochs = NUM_EPOCHS,\n",
        "      verbose = 1,\n",
        "      validation_data = validation_generator)\n",
        "\n",
        "# summarize history for accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.xlim([0,NUM_EPOCHS])\n",
        "plt.ylim([0.4,1.0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        }
      ]
    }
  ]
}